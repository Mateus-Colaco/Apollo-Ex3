# -*- coding: utf-8 -*-
"""Apollo_Ex3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cYBFPb_gDQLZntf5S8lkQjKH87FnSjCN
"""

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/ultralytics/yolov5  # clone repo
# %cd yolov5
!pip install -qr requirements.txt  # install dependencies (ignore errors)

from google.colab import drive
drive.mount('/content/drive')

import cv2
import torch
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
from PIL import Image, ImageDraw,ImageFont


class Detec:

  def __init__(self,video_path,shrinked_video_path,track,font_path,final_video_path):
    self.track = track
    self.final_video_path = final_video_path #directory to save final video
    self.font = ImageFont.truetype(font_path, 20)
    self.cap = cv2.VideoCapture(video_path)
    self.shrinked_video_path = shrinked_video_path
    fourcc_1 = cv2.VideoWriter_fourcc(*'mp4v')
    self.size = (960,800)
    self.fps = 25
    self.out = cv2.VideoWriter(shrinked_video_path,fourcc_1,self.fps,self.size)

    while True:
      success,frame = self.cap.read()
      if not success:
        break

      else:
        frame_resized = cv2.resize(frame,(size_X,size_Y),fx=0,fy=0)
        self.out.write(frame_resized)

    self.cap.release()
    self.out.release()
    
    
    return
         
#                                                              |#################################|
###############################################################|        HUMAN DETECTION          |###############################################################
#                                                              |#################################|

  def Human(self):
    self.Human_detection = True
    
    self.bgr_color = (0,255,255)
    self.human_coordinates = []
    self.human_limits_list = []
    self.first_append = 0
    self.Human_frames_to_video = list()
    self.human_model = torch.hub.load('ultralytics/yolov5', 'yolov5x')
    self.human_model.classes = [0]
    self.new_cap = cv2.VideoCapture(self.shrinked_video_path)
    while True:

      success,frames = self.new_cap.read()

      if not success:
        break
  
      self.human_bounding_box = self.human_model(frames)
      self.human_detec_number = self.human_bounding_box.pandas().xywh
      max_and_min = (self.human_bounding_box.pandas().xyxy[0]) # [xmin, ymin, xmax, ymax, confidence, class, name] all bounding boxes 

      if self.track:
        img = Image.fromarray(self.human_bounding_box.render()[0])
        draw = ImageDraw.Draw(img)
    
        for row in range(max_and_min['xmin'].count()):
          x_c = ( (max_and_min.iat[row,2] - max_and_min.iat[row,0]) / 2) + max_and_min.iat[row,0]
          y_c = ( (max_and_min.iat[row,3] - max_and_min.iat[row,1]) / 2) + max_and_min.iat[row,1]
          x_min_plot = max_and_min.iat[row,0]
          x_max  = 1.25*x_c
          x_min  = 0.75*x_c
          y_max = 1.22*y_c
          y_min = 0.8*y_c 

          if  self.first_append==0:
            self.human_limits_list.append( (x_max, x_min, y_max, y_min) )
            self.human_coordinates.append( (x_c,y_c) )
            self.first_append = 1

          else:
            for index,element in enumerate(self.human_limits_list):  
              x_max_test, x_min_test, y_max_test, y_min_test = element
              text=str(int(index))
              #if limits conditions True, new coordinate to existent ID
              if (x_c < x_max_test) and (x_c > x_min_test) and (y_c < y_max_test) and (y_c > y_min_test):
                if (x_c,y_c) in self.human_coordinates:
                  None
                else:
                  self.human_limits_list[index] = (x_max, x_min, y_max, y_min)
                  self.human_coordinates[index] = (x_c,y_c)
                  draw.text(     (x_min_plot ,y_c ), "ID."+ str(self.human_coordinates.index((x_c,y_c))),fill=self.bgr_color,font = self.font)
            if (x_c,y_c) in self.human_coordinates:
              None
            else:
              self.human_limits_list.append((x_max, x_min, y_max, y_min))
              self.human_coordinates.append((x_c,y_c))
              draw.text( (x_min_plot ,y_c ), "ID."+ str(self.human_coordinates.index((x_c,y_c))),fill=self.bgr_color,font = self.font)

      human_img = np.asarray(img)
  
      text_top = 'People Detected:' + str(np.shape(self.human_detec_number)[1])
      cv2.putText(human_img,text_top,(50,50),cv2.FONT_HERSHEY_DUPLEX, 1.1, (255,0,255), 1, cv2.LINE_AA)

      self.Human_frames_to_video.append(human_img)
    fourcc = cv2.VideoWriter_fourcc(*'XVID')
    
    if self.Human_detection == True:
      self.human_final_video = cv2.VideoWriter(self.final_video_path + "Track_Human.mp4",fourcc,fps,(size_X,size_Y))

      for frame in self.Human_frames_to_video:
        self.human_final_video.write(frame)

      self.human_final_video.release()

    return

#                                                              |#################################|
###############################################################|         RIFLE DETECTION         |#################################################################
#                                                              |#################################|

  def Rifle(self,weights_path):
    self.Rifle_detection = True
    self.bgr_color = (0,255,255)
    self.Rifle_coordinates = []
    self.Rifle_limits_list = []
    self.Rifle_first_append = 0
    self.Rifle_frames_to_video = list()
    self.Rifle_model = torch.hub.load('ultralytics/yolov5', 'custom',weights_path)
    self.new_cap = cv2.VideoCapture(self.shrinked_video_path)

    while True:
      success,frames = self.new_cap.read()

      if not success:
        break
  
      self.Rifle_bounding_box = self.Rifle_model(frames)
      self.Rifle_detec_number = self.Rifle_bounding_box.pandas().xywh
      max_and_min = (self.Rifle_bounding_box.pandas().xyxy[0]) # [xmin, ymin, xmax, ymax, confidence, class, name] all bounding boxes 

      if self.track:
        img = Image.fromarray(self.Rifle_bounding_box.render()[0])
        draw = ImageDraw.Draw(img)
    
        for row in range(max_and_min['xmin'].count()):
          x_c = ( (max_and_min.iat[row,2] - max_and_min.iat[row,0]) / 2) + max_and_min.iat[row,0]
          y_c = ( (max_and_min.iat[row,3] - max_and_min.iat[row,1]) / 2) + max_and_min.iat[row,1]
          x_min_plot = max_and_min.iat[row,0]
          x_max  = 1.1*x_c
          x_min  = 0.7*x_c
          y_max = 1.06*y_c
          y_min = 0.9*y_c 

          if  self.Rifle_first_append==0:
            self.Rifle_limits_list.append( (x_max, x_min, y_max, y_min) )
            self.Rifle_coordinates.append( (x_c,y_c) )
            self.Rifle_first_append = 1

          else:
            for index,element in enumerate(self.Rifle_limits_list):  
              x_max_test, x_min_test, y_max_test, y_min_test = element
              text=str(int(index))
              #if limits conditions True, new coordinate to existent ID
              if (x_c < x_max_test) and (x_c > x_min_test) and (y_c < y_max_test) and (y_c > y_min_test):
                if (x_c,y_c) in self.Rifle_coordinates:
                  None
                else:
                  self.Rifle_limits_list[index] = (x_max, x_min, y_max, y_min)
                  self.Rifle_coordinates[index] = (x_c,y_c)
                  draw.text(     (x_min_plot ,y_c ), "ID."+ str(self.Rifle_coordinates.index((x_c,y_c))),fill=self.bgr_color,font = self.font)
            if (x_c,y_c) in self.Rifle_coordinates:
              None
            else:
              self.Rifle_limits_list.append((x_max, x_min, y_max, y_min))
              self.Rifle_coordinates.append((x_c,y_c))
              draw.text( (x_min_plot ,y_c ), "ID."+ str(self.Rifle_coordinates.index((x_c,y_c))),fill=self.bgr_color,font = self.font)

      Rifle_img = np.asarray(img)
    
      text_top = 'Rifle Detected:' + str(np.shape(self.Rifle_detec_number)[1])
      cv2.putText(Rifle_img,text_top,(50,50),cv2.FONT_HERSHEY_DUPLEX, 1.1, (255,0,255), 1, cv2.LINE_AA)

      self.Rifle_frames_to_video.append(Rifle_img)

    fourcc = cv2.VideoWriter_fourcc(*'XVID')
    self.Rifle_final_video = cv2.VideoWriter(self.final_video_path + "Track_Rifle.mp4",fourcc,fps,(size_X,size_Y))

    for frame in self.Rifle_frames_to_video:
      self.Rifle_final_video.write(frame)

    self.Rifle_final_video.release()
    return


if __name__ == "__main__":

  Human_Tracker = Detec('/content/track_people.mp4','/content/shrinked_video.mp4',True,'/content/Amplesoft.ttf','/content/')
  Human_Tracker.Human()
  Rifle_Tracker = Detec('/content/drive/MyDrive/Colab Notebooks/video_ex02.mp4','/content/shrinked_video_2.mp4',True,'/content/Amplesoft.ttf','/content/')
  Rifle_Tracker.Rifle('/content/drive/MyDrive/Colab Notebooks/best_ex2.pt')

#(self,video_path,shrinked_video_path,track = True,font_path,final_video_path)